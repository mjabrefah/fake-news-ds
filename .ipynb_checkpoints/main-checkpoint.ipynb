{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e5c2389-5782-4dbf-8afe-34100b959d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake News - Make the required imports  \n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import itertools  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "from sklearn.linear_model import PassiveAggressiveClassifier  \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02690db4-0f66-43dd-8c00-5980868b0498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we read the data into a DataFrame (df) and get the shape of the data and the first 5 records  \n",
    "\n",
    "# Read the data  \n",
    "df = pd.read_csv('news.csv')  \n",
    "\n",
    "# Get the shape and head of the DataFrame  \n",
    "# 'shape' returns the number of rows and columns of the df  \n",
    "# 'head'  returns the header row and the first 5 rows or the specified number of rows\n",
    "df.shape  \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d53661b-e616-484b-9757-2e0dd8e266f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    FAKE\n",
       "1    FAKE\n",
       "2    REAL\n",
       "3    FAKE\n",
       "4    REAL\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fake News - Get the labels of the DataFrame  \n",
    "# unlike 'shape' or 'head', 'label' is already a part of the df\n",
    "labels = df.label\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a2d2fbf-8131-4409-9965-60ef46e2b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake News - Split the dataset into training sets and testing sets  \n",
    "\n",
    "# train_test_split() is used to split the data into training and testing sets  \n",
    "# df['test\"] is extracting the 'text' column from our DataFrame which has the text data we want to use for training and testing  \n",
    "# test_size parameter specifies the amount of your data you are allocating to your training set. Here we use 20%. The remaining 80% will be used for training  \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['text'], labels, test_size = 0.2, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67f7e707-cd81-496f-a420-f4e719060f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a TfidfVectorizer with stop words from the English language and a maximum document frequency of 0.7  \n",
    "# (Terms with a higher document frequency will be discarded. The reverse will be true for an inverse document frequency)  \n",
    "# **Stop words are the most common words in a language that need to be filtered out before processing the natural language data  \n",
    "\n",
    "# I'll need comments on the fit_transform and transform for better understanding\n",
    "\n",
    "# Fake News - Intializing a TfidfVectorizer  \n",
    "tfidf_vectorizer = TfidfVectorizer (stop_words = 'english', max_df = 0.7)  \n",
    "\n",
    "# Fake News - Fit and transform vectorizer on train set, transform vectorizer on test set  \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(x_train)  \n",
    "tfidf_test = tfidf_vectorizer.transform(x_test)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf297cbd-f31d-4bb2-8124-ebd6c5a5a322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.82%\n"
     ]
    }
   ],
   "source": [
    "# Next, intialize a PassiveAggressiveClassifier and fit it on tfidf_train and y_train  \n",
    "\n",
    "# Fake News - Initializing a PassiveAggressiveClassifier  \n",
    "pac = PassiveAggressiveClassifier(max_iter = 50)  \n",
    "pac.fit(tfidf_train, y_train)  \n",
    "\n",
    "# Fake News - Predict on the test set and calculate accuracy  \n",
    "y_pred = pac.predict(tfidf_test)  \n",
    "# print(y_pred)  \n",
    "score = accuracy_score(y_test, y_pred)  \n",
    "# print(score)  \n",
    "print(f'Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a276da6e-01ed-44eb-82f0-3afa59216042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[590,  48],\n",
       "       [ 43, 586]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With an accuracy of 92.82% with this model, \n",
    "# let's print out a confusion matrix to gain insight into the number of false and true negatives and positives  \n",
    "\n",
    "# Fake News - Build confusion matrix***  \n",
    "confusion_matrix(y_test, y_pred, labels = ['FAKE', 'REAL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eddd96-6534-4caf-a9e9-089d80f06e96",
   "metadata": {},
   "source": [
    "With this model, we have 590 true positives, 586 false positives, 48 false negatives and 43 false positives"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
